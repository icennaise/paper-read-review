# 1 Introduce
从实例中学习是许多NLP任务的主要方法。一个模型是在一组标记过的例子上训练的，然后从这些例子中归纳出未见过的数据。由于语言、领域和任务的数量庞大，以及注释数据的成本，在NLP的实际应用中，只有少量的标记例子是很常见的，这使得少量学习成为一个非常重要的研究领域。不幸的是，将标准的监督学习应用于小的训练集往往效果不佳；许多问题仅仅通过观察几个例子就很难掌握。例如，假设我们得到了以下的文本片段。

此外，设想我们被告知T1和T2的标签分别是l和l′，并要求我们推断出T3的正确标签。仅根据这些例子，这是不可能的，因为l和l′都可以找到可靠的理由。然而，如果我们知道基本任务是识别文本中是否有关于价格的内容，我们就可以很容易地将l′分配给T3。这说明，如果我们还有任务描述，即帮助我们理解任务内容的文本解释，那么仅凭几个例子就能解决一个任务就会变得容易得多。

随着GPT（Radford等人，2018）、BERT（Devlin等人，2019）和RoBERTa（Liu等人，2019）等预训练语言模型（PLM）的兴起，提供任务描述的想法对神经架构来说已经变得可行。我们可以简单地将这种描述用自然语言附加到输入中，让PLM预测解决该任务的连续性（Radford等人，2019；Puri和Catanzaro，2019）。到目前为止，这个想法大多被考虑在完全没有训练数据的零次方场景中。

在这项工作中，我们表明，提供任务描述可以成功地与标准的监督学习结合起来，在少数镜头的设置中。我们介绍了模式开发训练（PET），这是一个半监督的训练程序，它使用自然语言模式将输入的例子重新表述成cloze-style短语。如图1所示，PET的工作分为三个步骤。首先，在一个小的训练集T上对每个模式的单独PLM进行微调。然后，所有模式的集合被用来用软标签注释一个大的无标签数据集D。最后，在软标签的数据集上训练一个标准的分类器。我们还设计了iPET，这是PET的一个迭代变体，在这个过程中，随着训练集大小的增加，这个过程被重复。

在多语言的各种任务中，我们表明，只要有少量到中等数量的标记实例，PET和iPET的表现就大大超过了无监督方法、监督训练和强大的半监督基线。

# Related Work

Radford等人（2019）以自然语言模式的形式为阅读理解和问题回答（QA）等挑战性任务的零散学习提供提示。这一想法已被应用于无监督文本分类（Puri和Catanzaro，2019年）、常识性知识挖掘（Davison等人，2019年）和论证性重新分类（Opitz，2019年）。Srivastava等人（2018）使用任务描述进行零点分类，但需要一个语义分析器。对于关系提取，Bouraoui等人（2020）自动识别表达给定关系的模式。Mc- Cann等人（2018）将几个任务重新表述为QA问题。Raffel等人（2020年）将各种问题框定为语言建模任务，但他们的模式只是松散地类似于自然语言，不适合少数人的学习。

 最近的另一项工作是使用cloze-style短语来探测PLM在预训练期间获得的知识；这包括探测事实性和常识性知识（Trinh和Le，2018；Petroni等人，2019；Wang等人。2019年；Sakaguchi等人，2020年），语言能力（Ettinger，2020年；Kassner和Sch ̈̈，2020年），对罕见词汇的理解（Schick和Sch ̈，2020年），以及进行符号推理的能力（Talmor等人，2019年）。Jiang等人（2020年）考虑了寻找最佳模式来表达一个给定任务的问题。

NLP中的其他少数学习方法包括利用相关任务的例子（Yu等人，2018；Gu等人，2018；Dou等人，2019；Qian和Yu，2019；Yin等人，2019）和使用数据增强（Xie等人，2020；Chen等人，2020）；后者通常依赖于反向翻译（Sen- nrich等人，2016），需要大量的paral-lel数据。使用文本类描述符的方法通常假设丰富的例子可以用于一个类的子集（例如，Romera-Paredes和Torr，2015；Veeranna等人，2016；Ye等人，2020）。相比之下，我们的方法不需要额外的标记数据，并提供一个直观的界面来利用特定任务的人类知识。

iPET背后的想法--在前几代标注的数据上训练多代模型--与词义辨析（Yarowsky，1995）、关系提取（Brin，1999；Agichtein和Gravano，2000；Batista等人，2015）的自我训练和引导方法有相似之处。2015）、解析（McClosky等，2006；Re-ichart和Rappoport，2007；Huang和Harper，2009）、机器翻译（Hoang等，2018）和序列生成（He等，2020）。

# 3 Pattern-Exploiting Training

我们把任务A的输入写成一串短语x=（s1,...,sk），其中si∈V ∗；例如，如果A是文本推理（两个输入句子），k=2。我们将模式定义为一个函数P，它将x作为输入，并输出一个短语或句子P(x)∈V ∗，其中正好包含一个掩码标记，也就是说，它的输出可以被视为一个cloze question- tion。此外，我们把言语者定义为一个注入函数v：L→V，它把每个标签映射到M的词汇中的一个词。我们把(P,v)称为模式-言语者对(PVP)。

使用PVP（P,v）使我们能够解决任务A，具体如下。给定一个输入x，我们应用P来获得一个输入表示P(x)，然后由M处理，以确定v(y)最可能替代掩码的标签y∈L。例如，考虑识别两个句子a和b是否相互矛盾（标签y0）或相互同意（y1）的任务。对于这项任务，我们可以选择模式P(a,b)=a? b.结合一个口头禅v，将y0映射为 "是"，y1映射为 "否"。给出一个输入对的例子
x= (Mia likes pie, Mia hates pie),
现在的任务已经从分配一个没有内在意义的标签变成了回答是否最可能的选择是被掩盖的位置在
P(x) = Mia likes pie? , Mia hates pie。
是 "是 "还是 "不是"。

## 3.1 PVP Training and Inference

让p=（P,v）是一个PVP。对于每一个恰好包含一个掩码标记和w∈V的序列z∈V∗，我们用M(w | z)表示语言模型在掩码位置赋予w的非正常化分数。给定某个输入x，我们定义标签l∈L的分数为sp(l |x) = M(v(l) |P(x))，并使用softmax得到标签的概率分布。qp(l |x) = esp(l|x) ∑ l′∈Lesp(l′|x) 我们使用qp(l |x)和训练实例(x,l)的真实（一击）分布之间的交叉熵--在所有(x,l)∈T上求和--作为p的M微调损失。

## 3.2 Auxiliary Language Modeling

 在我们的应用场景中，只有少数训练样本是可用的，灾难性的遗忘可能发生。由于针对某些PVP进行微调的PLM的核心仍然是一个语言模型，我们通过使用语言建模作为辅助任务来解决这个问题。LCE表示交叉熵损失，LMLM表示语言建模损失，我们计算最终损失为L=（1-α）-LCE+α-LMLM。由于LMLM通常比LCE大得多，在初步的实验中，我们发现α=10-4的小值能持续给出良好的结果，所以我们在所有的实验中都使用了它。为了获得用于语言建模的句子，我们使用未标记的集合D。然而，我们并不直接对每个x∈D进行训练，而是对P(x)进行训练，我们从不要求语言模型对被屏蔽的槽进行任何预测。
 
## 3.3 Combining PVPs

我们的方法面临的一个关键挑战是，在没有大型开发集的情况下，很难确定哪些PVP表现良好。为了解决这个问题，我们使用了一种类似于知识提炼的策略（Hinton等人，2015）。首先，我们定义了一组PVP，这些PVP对给定的任务A来说是有意义的，然后我们使用这些PVP如下。(1) 如第3.1节所述，我们为每个P∈P微调一个单独的语言模型Mp。由于T很小，即使是大量的PVP，这种微调也很便宜。(2) 我们使用微调模型的集合M= {Mp|p∈P}来注释D中的例子。我们首先将每个例子x∈D的非归一化类别分数合并为sM(l |x) = 1 Z ∑ p∈P w(p) -sp(l |x) 其中Z = ∑ p∈P w(p) ，w(p)是PVPs的加权项。我们对这个加权项进行了两种不同的实验：要么我们简单地设置w(p)=1，要么我们设置w(p)为训练前使用p在训练集上保持的准确度。我们把这两种变体称为统一的和加权的。Jiang等人(2020)在零次拍摄的情况下使用了类似的想法。我们使用softmax将上述分数转化为proba-bility分布q。继Hinton等人（2015）之后，我们使用T=2的温度来获得一个合适的软分布。所有的配对（x,q）都被收集到一个（软标签的）训练集TC。(3) 我们在TC上用一个标准的序列分类头对PLM C进行微调。然后，经过微调的模型C作为我们对A的分类器。以上描述的所有步骤在图2中描述；一个例子在图1中显示。

## 3.4 Iterative PET (iPET)

将所有单个模型的知识提炼成一个单一的分类器C意味着它们不能相互学习。由于一些模式的表现（可能比其他模式差得多），因此我们最终模型的训练集TC可能包含许多错误标记的例子。为了弥补这一缺陷，我们设计了iPET，一个PET的迭代变体。iPET的核心思想是在越来越大的数据集上训练几代模型。为此，我们首先扩大原始数据集T，从D使用随机的PET模型的子集来标记选定的例子（图2a）。然后，我们在扩大的数据集上训练一个新的PET模型流派（b）；这个过程重复几次（c）。更正式地说，让M0={M01,...,M0n}是在T上进行微调的PET模型的初始集合，其中每个M0i是为某个PVP pi训练的。我们训练k代模型M1,...,Mk，其中Mj = {Mj 1,...,Mjn}，每个Mj i在它自己的训练集Tj i上为pi训练。在每个迭代中，我们将训练集的大小乘以一个固定的常数d∈N，同时保持原始数据集的标签比率。也就是说，c0(l)表示T中具有标签l的例子的数量，每个Tj i包含cj (l) = d -cj-1(l)具有标签l的例子。1. 我们通过从上一代中随机选择λ-(n -1)个模型，得到N⊂Mj-1\{Mj-1 i }，λ∈(0,1)是一个超参数。2. 2.使用这个子集，我们创建一个标记的数据集TN = {(x,arg maxl∈L sN(l |x)) |x∈D}。对于每个l∈L，我们通过从TN中随机选择具有标签l的cj(l)-c0(l)例子来获得TN(l)⊂TN。为了避免在错误标记的数据上训练后代，我们倾向于选择模型集合对其预测有信心的例子。其基本原理是，即使没有校准，标签被预测为高信心的例子通常更有可能被正确分类（Guo等人，2017）。因此，当从TN中提取时，我们将每个（x,y）的概率设定为与sN(l |x)成正比。3. 我们定义Tj i = T ∪⋃ l∈LTN（l）。可以很容易地验证，这个数据集包含每个l∈L的cj(l)例子。在训练了k代PET模型后，我们使用Mk来创建TC，并像基本PET那样训练C。经过细微的调整，iPET甚至可以在零次拍摄的情况下使用。为此，我们定义M0为未训练的模型集，c1(l)=10/|L||对于所有l∈L，所以M1是在10个例子上训练的，均匀地分布在所有标签上。由于TN可能不包含某些标签l的足够的例子，我们通过从sN(l | x)最高的100个例子x∈D中取样来创建所有TN(l)，即使l 6= arg maxl∈LsN(l | x)。对于随后的每一代，我们完全按照基本的iPET进行。

# 6
我们已经表明，向预训练的语言模型提供任务描述可以与标准的监督训练相结合。我们提出的方法，PET，包括定义cloze问题模式和言语者对，帮助利用预训练的语言模型中的知识来完成下游任务。我们对所有模式-言语者对进行微调，并使用它们来创建大型注释数据集，在这些数据集上可以训练标准的分类器。当最初的训练数据量有限时，PET比标准的监督训练和强大的半监督方法有很大改进。
