# 1 Introduce
从实例中学习是许多NLP任务的主要方法。一个模型是在一组标记过的例子上训练的，然后从这些例子中归纳出未见过的数据。由于语言、领域和任务的数量庞大，以及注释数据的成本，在NLP的实际应用中，只有少量的标记例子是很常见的，这使得少量学习成为一个非常重要的研究领域。不幸的是，将标准的监督学习应用于小的训练集往往效果不佳；许多问题仅仅通过观察几个例子就很难掌握。例如，假设我们得到了以下的文本片段。

此外，设想我们被告知T1和T2的标签分别是l和l′，并要求我们推断出T3的正确标签。仅根据这些例子，这是不可能的，因为l和l′都可以找到可靠的理由。然而，如果我们知道基本任务是识别文本中是否有关于价格的内容，我们就可以很容易地将l′分配给T3。这说明，如果我们还有任务描述，即帮助我们理解任务内容的文本解释，那么仅凭几个例子就能解决一个任务就会变得容易得多。

随着GPT（Radford等人，2018）、BERT（Devlin等人，2019）和RoBERTa（Liu等人，2019）等预训练语言模型（PLM）的兴起，提供任务描述的想法对神经架构来说已经变得可行。我们可以简单地将这种描述用自然语言附加到输入中，让PLM预测解决该任务的连续性（Radford等人，2019；Puri和Catanzaro，2019）。到目前为止，这个想法大多被考虑在完全没有训练数据的零次方场景中。

在这项工作中，我们表明，提供任务描述可以成功地与标准的监督学习结合起来，在少数镜头的设置中。我们介绍了模式开发训练（PET），这是一个半监督的训练程序，它使用自然语言模式将输入的例子重新表述成cloze-style短语。如图1所示，PET的工作分为三个步骤。首先，在一个小的训练集T上对每个模式的单独PLM进行微调。然后，所有模式的集合被用来用软标签注释一个大的无标签数据集D。最后，在软标签的数据集上训练一个标准的分类器。我们还设计了iPET，这是PET的一个迭代变体，在这个过程中，随着训练集大小的增加，这个过程被重复。

在多语言的各种任务中，我们表明，只要有少量到中等数量的标记实例，PET和iPET的表现就大大超过了无监督方法、监督训练和强大的半监督基线。
